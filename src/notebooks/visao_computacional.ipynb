{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laborátorio Visão Computacional\n",
    "\n",
    "Nesse lab tentarei demonstrar um pouco de como seria possível fazer um computador ver. Para tal, irei usar a biblioteca [**ultralytics**](https://docs.ultralytics.com/pt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Que Fizemos\n",
    "\n",
    "- Treinamento de Modelos\n",
    "  - Modelos Treinados\n",
    "    - Detecção do **Nome, Data de Nascimento, Data de Expedição, RG e CPF** para **documentos de identidade**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento de Modelos\n",
    "\n",
    "As imagens utilizadas no treinamento foram retiradas de [BID Dataset](https://github.com/ricardobnjunior/Brazilian-Identity-Document-Dataset).\n",
    "\n",
    "A ferramenta para marcação de imagens foi a [CVAT.ai](https://www.cvat.ai/)\n",
    "\n",
    "Separei 100 imagens dos documentos de RG, escolhi aquelas em que o documento estava na orientação *correta*. Fiz as marcações necessárias. Separei 70 imagens para treino, 30 para teste e validação.\n",
    "\n",
    "Os modelos gerados foram:\n",
    "\n",
    "- Modelo detecção RG Verso: **\\dataset\\documentos-pessoais\\rg-verso\\modelo_20240522**\n",
    "\n",
    "---\n",
    "Utilziando o [**YOLOv8**](https://docs.ultralytics.com/modes/) poderemos treinar um modelo com nossas imagens de maneira relativamente simples seguindo o seguinte pipeline\n",
    "- **Train**: Aperfeiçoar um modelo com dados personalizados.\n",
    "- **Val**: Verificar o desempenho do modelo.\n",
    "- **Predict**: Usar dados diferentes e ver o resultado do treinamento\n",
    "- **Export**: Exportar o modelo para uso posterior.\n",
    "- **Track**: Detectar os objetos em tempo real.\n",
    "- **Benchmark**: Analisar o modelo em diferentes ambientes. \n",
    "\n",
    "Meu objetivo não será desbravar todo o framework, e sim testar algumas coisas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train \n",
    "\n",
    "[Treinar](https://docs.ultralytics.com/modes/train/) nada mais é do que fazer o modelo aprender a detectar os objetos que marcamos em nossas imagens. Esse modo possui alguns hiperparâmetros, configurações.\n",
    "\n",
    "- model\n",
    "- data\n",
    "- epochs\n",
    "- time\n",
    "- patience\n",
    "- batch\n",
    "- imgsz\n",
    "- divice\n",
    "- project\n",
    "- name\n",
    "- exist_ok\n",
    "- pretrained\n",
    "- optimizer\n",
    "- verbose\n",
    "- seed\n",
    "- single_cls\n",
    "- rect\n",
    "- resume\n",
    "- freeze\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 475/475 items from pretrained weights\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov8m.yaml\").load(\"yolov8m.pt\") # Controi a partir de um YAML e tranfere os pessos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, treinamos o modelo com o yaml do projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.19 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.14  Python-3.11.4 torch-2.3.0+cpu CPU (Intel Xeon Gold 5118 2.30GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.yaml, data=./datasets/documentos-pessoais/rg-verso/documentos-pessoais-rg-verso.yaml, epochs=30, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train10, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train10\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3778591  ultralytics.nn.modules.head.Detect           [5, [192, 384, 576]]          \n",
      "YOLOv8m summary: 295 layers, 25859215 parameters, 25859199 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning \\\\BR004\\Usuários$\\rodrigo.goncalves\\Estudos\\Projetos\\rgbrain-lab-ocr\\rgbrain_lab_ocr\\datasets\\documentos-pessoais\\rg-verso\\train\\labels... 70 images, 0 backgrounds, 0 corrupt: 100%|██████████| 70/70 [00:01<00:00, 61.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: \\\\BR004\\Usurios$\\rodrigo.goncalves\\Estudos\\Projetos\\rgbrain-lab-ocr\\rgbrain_lab_ocr\\datasets\\documentos-pessoais\\rg-verso\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning \\\\BR004\\Usuários$\\rodrigo.goncalves\\Estudos\\Projetos\\rgbrain-lab-ocr\\rgbrain_lab_ocr\\datasets\\documentos-pessoais\\rg-verso\\valid\\labels... 30 images, 0 backgrounds, 0 corrupt: 100%|██████████| 30/30 [00:00<00:00, 69.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: \\\\BR004\\Usurios$\\rodrigo.goncalves\\Estudos\\Projetos\\rgbrain-lab-ocr\\rgbrain_lab_ocr\\datasets\\documentos-pessoais\\rg-verso\\valid\\labels.cache\n",
      "Plotting labels to runs\\detect\\train10\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train10\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30         0G      2.429      5.159      1.602         55        640: 100%|██████████| 5/5 [09:38<00:00, 115.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  NMS time limit 3.500s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:42<00:00, 42.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141      0.144     0.0778      0.061     0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30         0G      1.253      2.745      1.084         47        640: 100%|██████████| 5/5 [07:09<00:00, 85.82s/it] \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  NMS time limit 3.500s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:25<00:00, 25.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141      0.251      0.229       0.13     0.0824\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30         0G      1.096      1.867     0.9998         55        640: 100%|██████████| 5/5 [04:25<00:00, 53.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  NMS time limit 3.500s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:25<00:00, 25.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141      0.657      0.562      0.664      0.422\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30         0G     0.9688      1.247     0.9643         48        640: 100%|██████████| 5/5 [03:33<00:00, 42.63s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:24<00:00, 24.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141      0.793       0.79      0.869      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30         0G     0.9775      1.132     0.9677         42        640: 100%|██████████| 5/5 [03:50<00:00, 46.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:21<00:00, 21.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141      0.844      0.882       0.94       0.68\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30         0G     0.9603      1.066      0.964         42        640: 100%|██████████| 5/5 [04:57<00:00, 59.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:25<00:00, 25.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141      0.897      0.867      0.967      0.639\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30         0G     0.8929     0.8843     0.9491         44        640: 100%|██████████| 5/5 [02:56<00:00, 35.24s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:22<00:00, 22.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141      0.961      0.899      0.979      0.732\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30         0G     0.9007     0.7741     0.9248         53        640: 100%|██████████| 5/5 [03:36<00:00, 43.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:26<00:00, 26.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141       0.95      0.926       0.98      0.702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30         0G      0.891     0.7913     0.9376         41        640: 100%|██████████| 5/5 [03:05<00:00, 37.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:22<00:00, 22.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141      0.947      0.947      0.972      0.714\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30         0G     0.8589     0.6875     0.9129         67        640: 100%|██████████| 5/5 [03:00<00:00, 36.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:21<00:00, 21.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141      0.933      0.915      0.975      0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30         0G     0.8445     0.6393      0.924         55        640: 100%|██████████| 5/5 [02:44<00:00, 32.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:20<00:00, 20.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141      0.958      0.985       0.98      0.729\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30         0G     0.8769     0.6533     0.9291         48        640: 100%|██████████| 5/5 [03:05<00:00, 37.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:18<00:00, 18.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141      0.956      0.977      0.983      0.736\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30         0G     0.8197     0.6418     0.9077         44        640: 100%|██████████| 5/5 [02:42<00:00, 32.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:20<00:00, 20.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141      0.978      0.969      0.983      0.733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30         0G     0.8718      0.639     0.9073         37        640: 100%|██████████| 5/5 [03:53<00:00, 46.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:29<00:00, 29.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141      0.976       0.98      0.982      0.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30         0G     0.8256     0.5904     0.9031         51        640: 100%|██████████| 5/5 [03:21<00:00, 40.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:19<00:00, 19.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141      0.952      0.984      0.985      0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30         0G     0.9024     0.6082     0.9044         41        640: 100%|██████████| 5/5 [03:01<00:00, 36.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:20<00:00, 20.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141      0.972      0.984      0.984      0.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30         0G      0.974     0.6622     0.9372         47        640: 100%|██████████| 5/5 [03:12<00:00, 38.52s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:20<00:00, 20.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141       0.99      0.979      0.983      0.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30         0G     0.8743     0.6119     0.8935         54        640: 100%|██████████| 5/5 [03:33<00:00, 42.77s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:23<00:00, 23.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141       0.99      0.986      0.984      0.723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30         0G     0.9087     0.6113     0.9233         34        640: 100%|██████████| 5/5 [03:59<00:00, 47.96s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:22<00:00, 22.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141      0.975      0.985      0.983      0.733\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30         0G     0.8452     0.5982     0.9375         30        640: 100%|██████████| 5/5 [03:45<00:00, 45.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:20<00:00, 20.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141      0.955       0.99      0.983      0.752\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30         0G     0.8651     0.5647     0.9409         29        640: 100%|██████████| 5/5 [03:35<00:00, 43.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:24<00:00, 24.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141       0.98      0.989      0.984      0.758\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30         0G     0.8143     0.5556      0.934         29        640: 100%|██████████| 5/5 [05:35<00:00, 67.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:28<00:00, 29.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141       0.99      0.992      0.983      0.758\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30         0G     0.8216     0.5373     0.9308         30        640: 100%|██████████| 5/5 [04:01<00:00, 48.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:26<00:00, 26.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141       0.99      0.989      0.983      0.756\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30         0G     0.8104     0.5153     0.8994         28        640: 100%|██████████| 5/5 [03:59<00:00, 47.88s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:24<00:00, 24.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141      0.987      0.994      0.983       0.76\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30         0G     0.8209     0.5044     0.9085         28        640: 100%|██████████| 5/5 [03:46<00:00, 45.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:26<00:00, 26.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141      0.988      0.994      0.983      0.756\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30         0G      0.827     0.5042     0.9132         29        640: 100%|██████████| 5/5 [05:12<00:00, 62.57s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:28<00:00, 28.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141      0.989      0.994      0.983      0.772\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30         0G     0.7906     0.4749     0.8995         28        640: 100%|██████████| 5/5 [04:51<00:00, 58.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:29<00:00, 29.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141       0.99      0.994      0.984      0.775\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30         0G     0.8109     0.4816     0.8951         29        640: 100%|██████████| 5/5 [05:34<00:00, 66.83s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:30<00:00, 30.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141       0.99      0.994      0.984      0.777\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30         0G     0.7519     0.4684     0.8897         28        640: 100%|██████████| 5/5 [03:41<00:00, 44.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:26<00:00, 26.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141       0.99      0.994      0.984      0.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30         0G     0.7376     0.4492     0.8756         28        640: 100%|██████████| 5/5 [03:30<00:00, 42.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:22<00:00, 22.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141       0.99      0.994      0.984      0.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 epochs completed in 2.400 hours.\n",
      "Optimizer stripped from runs\\detect\\train10\\weights\\last.pt, 52.0MB\n",
      "Optimizer stripped from runs\\detect\\train10\\weights\\best.pt, 52.0MB\n",
      "\n",
      "Validating runs\\detect\\train10\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.14  Python-3.11.4 torch-2.3.0+cpu CPU (Intel Xeon Gold 5118 2.30GHz)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:21<00:00, 21.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141       0.99      0.994      0.984      0.778\n",
      "           nome_pessoa         30         29      0.966          1      0.965      0.784\n",
      "                    rg         30         30      0.998          1      0.995      0.781\n",
      "                   cpf         30         21      0.997          1      0.995      0.774\n",
      "       data_nascimento         30         31      0.997      0.968       0.97      0.747\n",
      "        data_expedicao         30         30      0.996          1      0.995      0.803\n",
      "Speed: 2.4ms preprocess, 606.3ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = model.train(data=\"./datasets/documentos-pessoais/rg-verso/documentos-pessoais-rg-verso.yaml\", epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois, verificamos se o modelo obteve um bom resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.14  Python-3.11.4 torch-2.3.0+cpu CPU (Intel Xeon Gold 5118 2.30GHz)\n",
      "YOLOv8m summary (fused): 218 layers, 25842655 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning \\\\BR004\\Usuários$\\rodrigo.goncalves\\Estudos\\Projetos\\rgbrain-lab-ocr\\rgbrain_lab_ocr\\datasets\\documentos-pessoais\\rg-verso\\valid\\labels.cache... 30 images, 0 backgrounds, 0 corrupt: 100%|██████████| 30/30 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:33<00:00, 16.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         30        141      0.991      0.994      0.984      0.779\n",
      "           nome_pessoa         30         29      0.966          1      0.965      0.784\n",
      "                    rg         30         30      0.998          1      0.995      0.782\n",
      "                   cpf         30         21      0.997          1      0.995      0.772\n",
      "       data_nascimento         30         31      0.997      0.968      0.969      0.744\n",
      "        data_expedicao         30         30      0.995          1      0.995      0.812\n",
      "Speed: 3.0ms preprocess, 1003.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train102\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7787683478425725"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = model.val()\n",
    "\n",
    "metrics.box.map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com tudo isso pronto, agora é a nossa hora de ver os resultado obtidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 nome_pessoa, 1 rg, 1 cpf, 1 data_nascimento, 1 data_expedicao, 2109.5ms\n",
      "Speed: 17.0ms preprocess, 2109.5ms inference, 51.0ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model(['datasets/documentos-pessoais/rg-verso/examples/00029411_in.jpg'])\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "    masks = result.masks\n",
    "    keypoints = result.keypoints\n",
    "    probs = result.probs\n",
    "    obb = result.obb\n",
    "    result.show()\n",
    "    result.save(\"teste.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar, devemos salvar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.14  Python-3.11.4 torch-2.3.0+cpu CPU (Intel Xeon Gold 5118 2.30GHz)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs\\detect\\train10\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 9, 8400) (49.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.3.0+cpu...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success  26.2s, saved as 'runs\\detect\\train10\\weights\\best.torchscript' (99.1 MB)\n",
      "\n",
      "Export complete (36.2s)\n",
      "Results saved to \u001b[1m\\\\BR004\\Usurios$\\rodrigo.goncalves\\Estudos\\Projetos\\rgbrain-lab-ocr\\rgbrain_lab_ocr\\runs\\detect\\train10\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=runs\\detect\\train10\\weights\\best.torchscript imgsz=640  \n",
      "Validate:        yolo val task=detect model=runs\\detect\\train10\\weights\\best.torchscript imgsz=640 data=./datasets/documentos-pessoais/rg-verso/documentos-pessoais-rg-verso.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'runs\\\\detect\\\\train10\\\\weights\\\\best.torchscript'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rgbrain-lab-ocr-8bxiftYE-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
